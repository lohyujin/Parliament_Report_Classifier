{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_opinions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Drop all Nan row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>category</th>\n",
       "      <th>per_curiam</th>\n",
       "      <th>case_name</th>\n",
       "      <th>date_filed</th>\n",
       "      <th>federal_cite_one</th>\n",
       "      <th>absolute_url</th>\n",
       "      <th>cluster</th>\n",
       "      <th>year_filed</th>\n",
       "      <th>scdb_id</th>\n",
       "      <th>scdb_decision_direction</th>\n",
       "      <th>scdb_votes_majority</th>\n",
       "      <th>scdb_votes_minority</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>31267</td>\n",
       "      <td>Justice Fuller</td>\n",
       "      <td>majority</td>\n",
       "      <td>False</td>\n",
       "      <td>Lambert v. Barrett</td>\n",
       "      <td>1895-11-25</td>\n",
       "      <td>159 U.S. 660</td>\n",
       "      <td>https://www.courtlistener.com/opinion/94293/la...</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v3/clus...</td>\n",
       "      <td>1895</td>\n",
       "      <td>1895-039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>By section 766 of the Revised Statutes, where ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author_name  category  per_curiam           case_name  date_filed  \\\n",
       "31267  Justice Fuller  majority       False  Lambert v. Barrett  1895-11-25   \n",
       "\n",
       "      federal_cite_one                                       absolute_url  \\\n",
       "31267     159 U.S. 660  https://www.courtlistener.com/opinion/94293/la...   \n",
       "\n",
       "                                                 cluster  year_filed  \\\n",
       "31267  https://www.courtlistener.com/api/rest/v3/clus...        1895   \n",
       "\n",
       "        scdb_id  scdb_decision_direction  scdb_votes_majority  \\\n",
       "31267  1895-039                      1.0                  8.0   \n",
       "\n",
       "       scdb_votes_minority                                               text  \n",
       "31267                  0.0  By section 766 of the Revised Statutes, where ...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all Nan\n",
    "df.dropna(inplace= True)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>category</th>\n",
       "      <th>per_curiam</th>\n",
       "      <th>case_name</th>\n",
       "      <th>date_filed</th>\n",
       "      <th>federal_cite_one</th>\n",
       "      <th>absolute_url</th>\n",
       "      <th>cluster</th>\n",
       "      <th>year_filed</th>\n",
       "      <th>scdb_id</th>\n",
       "      <th>scdb_decision_direction</th>\n",
       "      <th>scdb_votes_majority</th>\n",
       "      <th>scdb_votes_minority</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5131</td>\n",
       "      <td>Justice Fuller</td>\n",
       "      <td>majority</td>\n",
       "      <td>False</td>\n",
       "      <td>Tyler v. Cass County</td>\n",
       "      <td>1892-01-04</td>\n",
       "      <td>142 U.S. 288</td>\n",
       "      <td>https://www.courtlistener.com/opinion/93216/ty...</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v3/clus...</td>\n",
       "      <td>1892</td>\n",
       "      <td>1891-065</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This case comes before us on motion to dismiss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author_name  category  per_curiam             case_name  date_filed  \\\n",
       "5131  Justice Fuller  majority       False  Tyler v. Cass County  1892-01-04   \n",
       "\n",
       "     federal_cite_one                                       absolute_url  \\\n",
       "5131     142 U.S. 288  https://www.courtlistener.com/opinion/93216/ty...   \n",
       "\n",
       "                                                cluster  year_filed   scdb_id  \\\n",
       "5131  https://www.courtlistener.com/api/rest/v3/clus...        1892  1891-065   \n",
       "\n",
       "      scdb_decision_direction  scdb_votes_majority  scdb_votes_minority  \\\n",
       "5131                      1.0                  9.0                  0.0   \n",
       "\n",
       "                                                   text  \n",
       "5131  This case comes before us on motion to dismiss...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples=df.copy(deep=True)\n",
    "sample=samples[:5000]\n",
    "sample.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Removing stopwords and splitting into corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_list = stopwords.words('english')\n",
    "stop_list += ['court', 'law', 'claim', 'state', 'made', 'case', 'act', 'city', 'right', 'rights', 'defendant', 'may', \n",
    "              'would', 'one', 'plaintiff', 'upon', 'upon', 'said', 'shall', 'time', 'property', 'could', 'question', 'part', 'fact', 'company', 'held', 'statute', 'united', 'also', 'contract', 'order', 'land', 'power', 'must', 'judgment', '\\x97', 'party', 'make', 'without', 'whether', 'subject', 'might', 'purpose', 'provision', 'v.', 'congress', 'decision', 'court,', 'first', 'action', 'interest', 'evidence', 'within', 'two', 'tax', 'authority', 'case,', 'effect', 'person', 'it,', 'government', 'opinion', 'given', 'general', 'use', 'certain', 'cannot', 'that,', 'respect', 'required', 'amount', 'present', 'jurisdiction', 'thus', 'suit', 'proceeding', 'either', 'matter', 'found', 'rule', 'section', 'sale', 'term', 'state,', 'duty', 'title', 'district', 'ground', 'payment', '\"the', 'well', 'reason', 'commission', 'it.', 'united_states,', 'decree', 'charge', 'view', 'and,', 'grant', 'corporation', 'paid', 'new', 'taken', 'application', 'point', 'necessary', 'bank', 'another', 'show', 'condition', 'provided', 'used', 'give', 'unless']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sample['text']= sample['text'].apply(lambda x: [word.lower() for word in x.split() if word.lower() not in stop_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sample['text']= sample['text'].apply(lambda x: [lemmatizer.lemmatize(word.lower()) for word in x if lemmatizer.lemmatize(word.lower()) not in stop_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>category</th>\n",
       "      <th>per_curiam</th>\n",
       "      <th>case_name</th>\n",
       "      <th>date_filed</th>\n",
       "      <th>federal_cite_one</th>\n",
       "      <th>absolute_url</th>\n",
       "      <th>cluster</th>\n",
       "      <th>year_filed</th>\n",
       "      <th>scdb_id</th>\n",
       "      <th>scdb_decision_direction</th>\n",
       "      <th>scdb_votes_majority</th>\n",
       "      <th>scdb_votes_minority</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6169</td>\n",
       "      <td>Justice Brewer</td>\n",
       "      <td>majority</td>\n",
       "      <td>False</td>\n",
       "      <td>Sawyer v. Piper</td>\n",
       "      <td>1903-04-27</td>\n",
       "      <td>189 U.S. 154</td>\n",
       "      <td>https://www.courtlistener.com/opinion/95839/sa...</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v3/clus...</td>\n",
       "      <td>1903</td>\n",
       "      <td>1902-111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[leave, file, supplementary, answer, error, av...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author_name  category  per_curiam        case_name  date_filed  \\\n",
       "6169  Justice Brewer  majority       False  Sawyer v. Piper  1903-04-27   \n",
       "\n",
       "     federal_cite_one                                       absolute_url  \\\n",
       "6169     189 U.S. 154  https://www.courtlistener.com/opinion/95839/sa...   \n",
       "\n",
       "                                                cluster  year_filed   scdb_id  \\\n",
       "6169  https://www.courtlistener.com/api/rest/v3/clus...        1903  1902-111   \n",
       "\n",
       "      scdb_decision_direction  scdb_votes_majority  scdb_votes_minority  \\\n",
       "6169                      1.0                  9.0                  0.0   \n",
       "\n",
       "                                                   text  \n",
       "6169  [leave, file, supplementary, answer, error, av...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yujin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# sample['sent_list'] = sample['sent_list'].apply(lambda x: [gensim.models.phrases.Phrases(x, min_count=3, threshold=10)])\n",
    "import gensim \n",
    "\n",
    "doc = sample['text'].values.tolist()\n",
    "bi = gensim.models.phrases.Phrases(doc, min_count=3, threshold=10)\n",
    "tri = gensim.models.phrases.Phrases(bi[doc], min_count=3, threshold=10)\n",
    "sample['text'] = tri[bi[doc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem=sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>category</th>\n",
       "      <th>per_curiam</th>\n",
       "      <th>case_name</th>\n",
       "      <th>date_filed</th>\n",
       "      <th>federal_cite_one</th>\n",
       "      <th>absolute_url</th>\n",
       "      <th>cluster</th>\n",
       "      <th>year_filed</th>\n",
       "      <th>scdb_id</th>\n",
       "      <th>scdb_decision_direction</th>\n",
       "      <th>scdb_votes_majority</th>\n",
       "      <th>scdb_votes_minority</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1787</td>\n",
       "      <td>Justice Reed</td>\n",
       "      <td>majority</td>\n",
       "      <td>False</td>\n",
       "      <td>United States v. Petty Motor Co.</td>\n",
       "      <td>1946-03-25</td>\n",
       "      <td>327 U.S. 372</td>\n",
       "      <td>https://www.courtlistener.com/opinion/104248/u...</td>\n",
       "      <td>https://www.courtlistener.com/api/rest/v3/clus...</td>\n",
       "      <td>1946</td>\n",
       "      <td>1945-048</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[writ_certiorari, judicial_code, §_240, brings...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_name  category  per_curiam                         case_name  \\\n",
       "1787  Justice Reed  majority       False  United States v. Petty Motor Co.   \n",
       "\n",
       "      date_filed federal_cite_one  \\\n",
       "1787  1946-03-25     327 U.S. 372   \n",
       "\n",
       "                                           absolute_url  \\\n",
       "1787  https://www.courtlistener.com/opinion/104248/u...   \n",
       "\n",
       "                                                cluster  year_filed   scdb_id  \\\n",
       "1787  https://www.courtlistener.com/api/rest/v3/clus...        1946  1945-048   \n",
       "\n",
       "      scdb_decision_direction  scdb_votes_majority  scdb_votes_minority  \\\n",
       "1787                      2.0                  7.0                  0.0   \n",
       "\n",
       "                                                   text  \n",
       "1787  [writ_certiorari, judicial_code, §_240, brings...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lem.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['upon', 'said', 'shall', 'time', 'property', 'could', 'question', 'part', 'fact', 'company', 'held', 'statute', 'united', 'also', 'contract', 'order', 'land', 'power', 'must', 'judgment', '\\x97', 'party', 'make', 'without', 'whether', 'subject', 'might', 'purpose', 'provision', 'v.', 'congress', 'decision', 'court,', 'first', 'action', 'interest', 'evidence', 'within', 'two', 'tax', 'authority', 'case,', 'effect', 'person', 'it,', 'government', 'opinion', 'given', 'general', 'use', 'certain', 'cannot', 'that,', 'respect', 'required', 'amount', 'present', 'jurisdiction', 'thus', 'suit', 'proceeding', 'either', 'matter', 'found', 'rule', 'section', 'sale', 'term', 'state,', 'duty', 'title', 'district', 'ground', 'payment', '\"the', 'well', 'reason', 'commission', 'it.', 'united_states,', 'decree', 'charge', 'view', 'and,', 'grant', 'corporation', 'paid', 'new', 'taken', 'application', 'point', 'necessary', 'bank', 'another', 'show', 'condition', 'provided', 'used', 'give', 'unless'])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "doc_lem = df_lem['text'].values.tolist()\n",
    "\n",
    "a = []\n",
    "\n",
    "for i in doc_lem:\n",
    "    a += i\n",
    "\n",
    "\n",
    "# Pass the split_it list to instance of Counter class. \n",
    "Counter = Counter(a) \n",
    "  \n",
    "# most_common() produces k frequently encountered \n",
    "# input values and their respective counts. \n",
    "most_occur = Counter.most_common(100) \n",
    "\n",
    "def Convert(tup, di): \n",
    "    for a, b in tup: \n",
    "        di.setdefault(a, []).append(b) \n",
    "    return di \n",
    "dictionary = {}\n",
    "asd = Convert(most_occur, dictionary)\n",
    "print(asd.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1) Create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4.1.1) Create list from dataframe <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 lemmatise only\n",
    "doc_lem= df_lem['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4.1.2) Create dictionary <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_lem=corpora.Dictionary(doc_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id2=dict_lem.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4.1.3) TF <b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_lem= [dict_lem.doc2bow(doc) for doc in doc_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the LDA model with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1) LDA with term freq (tf)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_reviews_lem= gensim.models.ldamodel.LdaModel(corpus=vec_lem, id2word=dict_lem, num_topics=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.001*\"brought\" + 0.001*\"record\" + 0.001*\"states,\" + 0.001*\"liability\" + 0.001*\"public\" + 0.001*\"account\" + 0.001*\"see\" + 0.001*\"think\" + 0.001*\"creditor\" + 0.001*\"result\" + 0.001*\"considered\" + 0.001*\"appeal\" + 0.001*\"owner\" + 0.001*\"policy\" + 0.001*\"petitioner\"')\n",
      "(1, '0.003*\"states,\" + 0.002*\"regulation\" + 0.001*\"trial\" + 0.001*\"article\" + 0.001*\"officer\" + 0.001*\"word\" + 0.001*\"good\" + 0.001*\"although\" + 0.001*\"every\" + 0.001*\"therefore\" + 0.001*\"particular\" + 0.001*\"policy\" + 0.001*\"think\" + 0.001*\"states.\" + 0.001*\"rate\"')\n",
      "(2, '0.002*\"company,\" + 0.002*\"business\" + 0.001*\"public\" + 0.001*\"agreement\" + 0.001*\"railroad\" + 0.001*\"pay\" + 0.001*\"consideration\" + 0.001*\"making\" + 0.001*\"stated\" + 0.001*\"property,\" + 0.001*\"whole\" + 0.001*\"lease\" + 0.001*\"construction\" + 0.001*\"take\" + 0.001*\"estate\"')\n",
      "(3, '0.003*\"patent\" + 0.002*\"circuit\" + 0.002*\"bond\" + 0.002*\"cause\" + 0.001*\"brought\" + 0.001*\"is,\" + 0.001*\"them,\" + 0.001*\"record\" + 0.001*\"possession\" + 0.001*\"states,\" + 0.001*\"bill\" + 0.001*\"claimed\" + 0.001*\"error\" + 0.001*\"entitled\" + 0.001*\"proper\"')\n",
      "(4, '0.003*\"water\" + 0.003*\"river\" + 0.002*\"public\" + 0.002*\"states,\" + 0.001*\"vessel\" + 0.001*\"line\" + 0.001*\"owner\" + 0.001*\"navigation\" + 0.001*\"place\" + 0.001*\"project\" + 0.001*\"flood\" + 0.001*\"way\" + 0.001*\"although\" + 0.001*\"survey\" + 0.001*\"dam\"')\n",
      "(5, '0.003*\"appeal\" + 0.002*\"petitioner\" + 0.002*\"states,\" + 0.002*\"circuit\" + 0.002*\"cause\" + 0.001*\"judge\" + 0.001*\"record\" + 0.001*\"vessel\" + 0.001*\"trial\" + 0.001*\"court.\" + 0.001*\"error\" + 0.001*\"owner\" + 0.001*\"cargo\" + 0.001*\"appellant\" + 0.001*\"supreme\"')\n",
      "(6, '0.002*\"railroad\" + 0.001*\"estate\" + 0.001*\"value\" + 0.001*\"states,\" + 0.001*\"is,\" + 0.001*\"account\" + 0.001*\"business\" + 0.001*\"according\" + 0.001*\"line\" + 0.001*\"even\" + 0.001*\"much\" + 0.001*\"circuit\" + 0.001*\"form\" + 0.001*\"word\" + 0.001*\"proper\"')\n",
      "(7, '0.004*\"railroad\" + 0.003*\"rate\" + 0.002*\"carrier\" + 0.002*\"line\" + 0.002*\"interstate_commerce\" + 0.002*\"car\" + 0.002*\"transportation\" + 0.001*\"finding\" + 0.001*\"although\" + 0.001*\"business\" + 0.001*\"except\" + 0.001*\"good\" + 0.001*\"service\" + 0.001*\"construction\" + 0.001*\"shipper\"')\n",
      "(8, '0.002*\"railroad\" + 0.002*\"business\" + 0.002*\"see\" + 0.002*\"federal\" + 0.001*\"since\" + 0.001*\"stock\" + 0.001*\"appellant\" + 0.001*\"board\" + 0.001*\"petitioner\" + 0.001*\"result\" + 0.001*\"value\" + 0.001*\"agreement\" + 0.001*\"§\" + 0.001*\"way\" + 0.001*\"._._.\"')\n",
      "(9, '0.002*\"federal\" + 0.002*\"brought\" + 0.002*\"states,\" + 0.002*\"railroad\" + 0.001*\"pay\" + 0.001*\"respondent\" + 0.001*\"circuit\" + 0.001*\"construction\" + 0.001*\"petitioner\" + 0.001*\"board\" + 0.001*\"act,\" + 0.001*\"court.\" + 0.001*\"law,\" + 0.001*\"cause\" + 0.001*\"intended\"')\n"
     ]
    }
   ],
   "source": [
    "topics_lem=lda_reviews_lem.show_topics(12,15)\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(topics_lem[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Optimal Number of the Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1) Model with tf vectors - DONT RUN THIS<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-26 16:41:00.401077\n",
      "#Topics: 2 Score: 0.2638833291549765\n",
      "#Topics: 4 Score: 0.2667767666483527\n",
      "#Topics: 6 Score: 0.2663717329493514\n",
      "#Topics: 8 Score: 0.2656337780085692\n",
      "#Topics: 10 Score: 0.27136799272610207\n",
      "#Topics: 12 Score: 0.2812567583644125\n",
      "2020-09-26 17:02:50.345578\n"
     ]
    }
   ],
   "source": [
    "# Can take a long time to run. In this case we are going to  k_max=10.\n",
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "model_list = []\n",
    "coherence_values = []\n",
    "model_topics = []\n",
    "\n",
    "for num_topics in range(2, 14, 2):\n",
    "    #sg_lda_x = gensim.models.ldamodel.LdaModel(corpus=sg_vecs, id2word=sg_dictionary, num_topics=num_topics)\n",
    "    lda_reviews_lem= gensim.models.ldamodel.LdaModel(corpus=vec_lem, id2word=dict_lem, num_topics=num_topics, iterations=1000, random_state=100)\n",
    "    coherencemodel = CoherenceModel(model=lda_reviews_lem, texts=doc_lem, dictionary=dict_lem, coherence='c_v')\n",
    "    model_topics.append(num_topics)\n",
    "    model_list.append(lda_reviews_lem)\n",
    "    coherence_values.append(coherencemodel.get_coherence())\n",
    "    print(\"#Topics: \" + str(num_topics) + \" Score: \" + str(coherencemodel.get_coherence()))\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "limit=14; start=2; step=2;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.2639\n",
      "Num Topics = 4  has Coherence Value of 0.2668\n",
      "Num Topics = 6  has Coherence Value of 0.2664\n",
      "Num Topics = 8  has Coherence Value of 0.2656\n",
      "Num Topics = 10  has Coherence Value of 0.2714\n",
      "Num Topics = 12  has Coherence Value of 0.2813\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>- END HERE BECAUSE RESULT ARE NOT GOOD-<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence Score - dont think need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score LDA-lem:  0.2812567583644125\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence score for lemmatising -tf only\n",
    "coherence_model_lda_lem = CoherenceModel(model=lda_reviews_lem, texts=doc_lem, dictionary=dict_lem, coherence='c_v')\n",
    "coherence_lda_lem = coherence_model_lda_lem.get_coherence()\n",
    "print('\\nCoherence Score LDA-lem: ', coherence_lda_lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.001*\"brought\" + 0.001*\"record\" + 0.001*\"states,\" + 0.001*\"liability\" + '\n",
      "  '0.001*\"public\" + 0.001*\"account\" + 0.001*\"see\" + 0.001*\"think\" + '\n",
      "  '0.001*\"creditor\" + 0.001*\"result\"'),\n",
      " (1,\n",
      "  '0.003*\"states,\" + 0.002*\"regulation\" + 0.001*\"trial\" + 0.001*\"article\" + '\n",
      "  '0.001*\"officer\" + 0.001*\"word\" + 0.001*\"good\" + 0.001*\"although\" + '\n",
      "  '0.001*\"every\" + 0.001*\"therefore\"'),\n",
      " (2,\n",
      "  '0.002*\"company,\" + 0.002*\"business\" + 0.001*\"public\" + 0.001*\"agreement\" + '\n",
      "  '0.001*\"railroad\" + 0.001*\"pay\" + 0.001*\"consideration\" + 0.001*\"making\" + '\n",
      "  '0.001*\"stated\" + 0.001*\"property,\"'),\n",
      " (3,\n",
      "  '0.003*\"patent\" + 0.002*\"circuit\" + 0.002*\"bond\" + 0.002*\"cause\" + '\n",
      "  '0.001*\"brought\" + 0.001*\"is,\" + 0.001*\"them,\" + 0.001*\"record\" + '\n",
      "  '0.001*\"possession\" + 0.001*\"states,\"'),\n",
      " (4,\n",
      "  '0.003*\"water\" + 0.003*\"river\" + 0.002*\"public\" + 0.002*\"states,\" + '\n",
      "  '0.001*\"vessel\" + 0.001*\"line\" + 0.001*\"owner\" + 0.001*\"navigation\" + '\n",
      "  '0.001*\"place\" + 0.001*\"project\"'),\n",
      " (5,\n",
      "  '0.003*\"appeal\" + 0.002*\"petitioner\" + 0.002*\"states,\" + 0.002*\"circuit\" + '\n",
      "  '0.002*\"cause\" + 0.001*\"judge\" + 0.001*\"record\" + 0.001*\"vessel\" + '\n",
      "  '0.001*\"trial\" + 0.001*\"court.\"'),\n",
      " (6,\n",
      "  '0.002*\"railroad\" + 0.001*\"estate\" + 0.001*\"value\" + 0.001*\"states,\" + '\n",
      "  '0.001*\"is,\" + 0.001*\"account\" + 0.001*\"business\" + 0.001*\"according\" + '\n",
      "  '0.001*\"line\" + 0.001*\"even\"'),\n",
      " (7,\n",
      "  '0.004*\"railroad\" + 0.003*\"rate\" + 0.002*\"carrier\" + 0.002*\"line\" + '\n",
      "  '0.002*\"interstate_commerce\" + 0.002*\"car\" + 0.002*\"transportation\" + '\n",
      "  '0.001*\"finding\" + 0.001*\"although\" + 0.001*\"business\"'),\n",
      " (8,\n",
      "  '0.002*\"railroad\" + 0.002*\"business\" + 0.002*\"see\" + 0.002*\"federal\" + '\n",
      "  '0.001*\"since\" + 0.001*\"stock\" + 0.001*\"appellant\" + 0.001*\"board\" + '\n",
      "  '0.001*\"petitioner\" + 0.001*\"result\"'),\n",
      " (9,\n",
      "  '0.002*\"federal\" + 0.002*\"brought\" + 0.002*\"states,\" + 0.002*\"railroad\" + '\n",
      "  '0.001*\"pay\" + 0.001*\"respondent\" + 0.001*\"circuit\" + 0.001*\"construction\" + '\n",
      "  '0.001*\"petitioner\" + 0.001*\"board\"'),\n",
      " (10,\n",
      "  '0.003*\"note\" + 0.003*\"states,\" + 0.002*\"public\" + 0.002*\"bill\" + '\n",
      "  '0.002*\"money\" + 0.002*\"every\" + 0.001*\"is,\" + 0.001*\"bank,\" + '\n",
      "  '0.001*\"express\" + 0.001*\"error\"'),\n",
      " (11,\n",
      "  '0.001*\"petitioner\" + 0.001*\"respondent\" + 0.001*\"assessment\" + '\n",
      "  '0.001*\"notice\" + 0.001*\"commissioner\" + 0.001*\"received\" + 0.001*\"federal\" '\n",
      "  '+ 0.001*\"railroad\" + 0.001*\"states,\" + 0.001*\"return\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "optimal_model = lda_reviews_lem\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Dominant Topic for each Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>court, upon, case, made, would, said, may, one...</td>\n",
       "      <td>[case, brought, appeal_decree_circuit, court, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>said, upon, court, land, made, company, case, ...</td>\n",
       "      <td>[plaintiff_error,_plaintiff_below,, commenced_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>court, case, upon, may, state, defendant, one,...</td>\n",
       "      <td>[whether, state, court, circuit_court_united_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>said, upon, court, land, made, company, case, ...</td>\n",
       "      <td>[writ_error_circuit_court, united_state_distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>court, upon, case, made, would, said, may, one...</td>\n",
       "      <td>[case, present, single, point, consideration.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>court, upon, case, made, would, said, may, one...</td>\n",
       "      <td>[seen, fact, case, plaintiff, default, account...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.6452</td>\n",
       "      <td>said, upon, court, land, made, company, case, ...</td>\n",
       "      <td>[suit_foreclose, railroad, mortgage, incidenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.7021</td>\n",
       "      <td>court, upon, case, made, would, said, may, one...</td>\n",
       "      <td>[stating, case,, proceeded:, 32, several_objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5099</td>\n",
       "      <td>said, upon, court, land, made, company, case, ...</td>\n",
       "      <td>[suit_brought, united_state, supreme_court_dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>tax, state, upon, may, one, property, case, wo...</td>\n",
       "      <td>[whether, utah, submitted, suit, united_state,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             0            10.0              0.9933   \n",
       "1             1             7.0              0.2333   \n",
       "2             2             5.0              0.3044   \n",
       "3             3             7.0              0.8122   \n",
       "4             4            10.0              0.9971   \n",
       "..          ...             ...                 ...   \n",
       "95           95            10.0              0.9853   \n",
       "96           96             7.0              0.6452   \n",
       "97           97            10.0              0.7021   \n",
       "98           98             7.0              0.5099   \n",
       "99           99            11.0              0.4919   \n",
       "\n",
       "                                             Keywords  \\\n",
       "0   court, upon, case, made, would, said, may, one...   \n",
       "1   said, upon, court, land, made, company, case, ...   \n",
       "2   court, case, upon, may, state, defendant, one,...   \n",
       "3   said, upon, court, land, made, company, case, ...   \n",
       "4   court, upon, case, made, would, said, may, one...   \n",
       "..                                                ...   \n",
       "95  court, upon, case, made, would, said, may, one...   \n",
       "96  said, upon, court, land, made, company, case, ...   \n",
       "97  court, upon, case, made, would, said, may, one...   \n",
       "98  said, upon, court, land, made, company, case, ...   \n",
       "99  tax, state, upon, may, one, property, case, wo...   \n",
       "\n",
       "                                                 Text  \n",
       "0   [case, brought, appeal_decree_circuit, court, ...  \n",
       "1   [plaintiff_error,_plaintiff_below,, commenced_...  \n",
       "2   [whether, state, court, circuit_court_united_s...  \n",
       "3   [writ_error_circuit_court, united_state_distri...  \n",
       "4   [case, present, single, point, consideration.,...  \n",
       "..                                                ...  \n",
       "95  [seen, fact, case, plaintiff, default, account...  \n",
       "96  [suit_foreclose, railroad, mortgage, incidenta...  \n",
       "97  [stating, case,, proceeded:, 32, several_objec...  \n",
       "98  [suit_brought, united_state, supreme_court_dis...  \n",
       "99  [whether, utah, submitted, suit, united_state,...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find most dominant topic\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def format_topics_sentences(ldamodel, corpus, data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(data)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "#I choose model_list[1] where the number of topics is 4\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=vec_lem, data=doc_lem)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a model to disk, or reload a pre-trained model\n",
    "import pickle\n",
    "\n",
    "# lda_lem_tfidf.save(\"lda\")\n",
    "\n",
    "ldapickle = open('ldapickle', \"wb\")\n",
    "pickle.dump(optimal_model, ldapickle)\n",
    "ldapickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "reader = open(\"ldamallet_model478927.pickle\", \"rb\")\n",
    "tester_model = pickle.load(reader)\n",
    "topics_lem=tester_model.show_topics(10,15)\n",
    "topics_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST NEW DATA\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora\n",
    "import pickle\n",
    "\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "stop_list = stopwords.words('english')\n",
    "stop_list += ['hotel', 'however', 'could', 'get', 'back', 'bit', 'one', 'know', 'i', 'have', 'would', 'take', 'a', 'choose', 'the', 'first', 'second', 'lovely', 'will', 'definitely', 'longer', 'stayed', 'also']\n",
    "\n",
    "def preprocessing(review):\n",
    "    sentences = review.split(\". \")\n",
    "    data = [[word.lower() for word in x.split() if word.lower() not in stop_list] for x in sentences]\n",
    "#     lem = [[lemmatizer.lemmatize(w) for w in doc] for doc in data]\n",
    "    dict_lem=corpora.Dictionary(data)\n",
    "    token_to_id2=dict_lem.token2id\n",
    "    vec_lem= [dict_lem.doc2bow(doc) for doc in data]\n",
    "    \n",
    "    return vec_lem\n",
    "\n",
    "unseen_rev= preprocessing(\"room and bed is spacious. shower old put room water. staff friendly reception room helpful bar.\")\n",
    "\n",
    "for sen in unseen_rev:\n",
    "#     tester_model is the lda model that you load with pickle\n",
    "    result=tester_model[sen]\n",
    "    result = sorted(result, key=lambda x: x[1], reverse=True)\n",
    "    topic = result[0][0]\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "\n",
    "classifier_saved = open(\"ldamallet_model478927.pickle\", \"rb\") #binary read\n",
    "tester_model = pickle.load(classifier_saved)\n",
    "classifier_saved.close()\n",
    "\n",
    "# TEST NEW DATA\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora\n",
    "import pickle\n",
    "\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "stop_list = stopwords.words('english')\n",
    "stop_list += ['hotel', 'however', 'could', 'get', 'back', 'bit', 'one', 'know', 'i', 'have', 'would', 'take', 'a', 'choose', 'the', 'first', 'second', 'lovely', 'will', 'definitely', 'longer', 'stayed', 'also']\n",
    "\n",
    "def preprocessing(review):\n",
    "    sentences = review.split(\". \")\n",
    "    data = [[word.lower() for word in x.split() if word.lower() not in stop_list] for x in sentences]\n",
    "#     lem = [[lemmatizer.lemmatize(w) for w in doc] for doc in data]\n",
    "    dict_lem=corpora.Dictionary(data)\n",
    "    token_to_id2=dict_lem.token2id\n",
    "    vec_lem= [dict_lem.doc2bow(doc) for doc in data]\n",
    "    \n",
    "    return vec_lem\n",
    "\n",
    "unseen_rev= preprocessing(\"room and bed is spacious. shower old put room water. staff friendly reception room helpful bar.\")\n",
    "\n",
    "gensim_lda = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(tester_model)\n",
    "\n",
    "# print(unseen_rev)\n",
    "for sen in unseen_rev:\n",
    "#     tester_model is the lda model that you load with pickle\n",
    "    result=gensim_lda[sen]\n",
    "    result = sorted(result, key=lambda x: x[1], reverse=True)\n",
    "    topic = result[0][0]\n",
    "    print(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
